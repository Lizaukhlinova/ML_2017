{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bias-variance-noise decomposition\n",
    "\n",
    "Необходимо доказать, что:\n",
    "\n",
    "$E_{x,y}E_{X^l}(y - a_{X^l}(x))^2 = \\underbrace{E_{x,y}(y - E(y|x))^2}_{\\text{noise}} + \\underbrace{E_{x_y}(E(y|x) - E_{X^l}a_{X^l}(x))^2}_{\\text{bias}} + \\underbrace{E_{x,y}E_{X^l}(a_{X^l}(x) - E_{X^l}a_{X^l}(x))^2}_{\\text{variance}}$\n",
    "\n",
    "Раскроем скобки слева:\n",
    "\n",
    "$E_{x,y}E_{X^l}(y - a_{X^l}(x))^2 = E_{x,y}E_{X^l}(y - E_{X^l}a_{X^l}(x) + E_{X^l}a_{X^l}(x) - a_{X^l}(x))^2 = E_{x,y}E_{X^l}(y - E_{X^l}a_{X^l}(x))^2 + \\underbrace{2E_{x,y}E_{X^l}(y - E_{X^l}a_{X^l}(x))(E_{X^l}a_{X^l}(x) - a_{X^l}(x))}_{\\text{0}} + \\underbrace{E_{x,y}E_{X^l}(a_{X^l}(x) - E_{X^l}a_{X^l}(x))^2}_{\\text{variance}} = E_{x,y}E_{X^l}(y - E_{X^l}a_{X^l}(x))^2 + Variance = E_{x,y}E_{X^l}(y - E(y|x) + E(y|x) - E_{X^l}a_{X^l}(x))^2 + Variance =  \\underbrace{E_{x,y}(y - E(y|x))^2}_{\\text{noise}} + \\underbrace{2 E_{x,y}E_{X^l}(y - E(y|x))(E(y|x) - E_{X^l}a_{X^l}(x))}_{\\text{0}} + \\underbrace{E_{x_y}(E(y|x) - E_{X^l}a_{X^l}(x))^2}_{\\text{bias}} + Variance = Noise + Bias + Variance$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Смещение и разброс в бэггинге\n",
    "\n",
    "$Bias_i = E(\\hat{y_i}-y)$\n",
    "\n",
    "$\\hat{y} = \\frac{1}{n}\\sum_{i=1}^n\\hat{y_i}$\n",
    "\n",
    "$Bias = E(\\hat{y} - y) = E\\hat{y}-Ey = \\frac{1}{n}\\sum_{i=1}^nE\\hat{y_i} - y = Bias_1$\n",
    "\n",
    "То есть мы получили, что bias не изменяется.\n",
    "\n",
    "$Var_i = E(\\hat{y_i} - y)^2$\n",
    "\n",
    "$Var = E(\\hat{y} - y)^2 = \\frac{1}{n^2}E(\\sum_{i=1}^n(\\hat{y_i} - y))^2 = \\frac{1}{n^2}(\\sum_{i=1}^nE(\\hat{y_i} - y)^2 + \\sum_{i\\neq j}^nE(\\hat{y_i} - y)(\\hat{y_j} - y))$\n",
    "\n",
    "Для нескоррелированных деревьев $Var = \\frac{1}{n^2}(\\sum_{i=1}^nE(\\hat{y_i} - y)^2) = \\frac{\\sigma^2}{n}$.\n",
    "\n",
    "Для скоррелированных деревьев $E(\\hat{y_i} - y)(\\hat{y_j} - y) \\leq E(\\hat{y_i} - y)E(\\hat{y_j} - y) = \\sigma^2$. Значит, $Var \\leq \\frac{1}{n^2}(n \\sigma^2 + M(M-1)\\sigma^2) = \\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Корреляция ответов базовых алгоритмов\n",
    "\n",
    "Рассмотрим M одинаково распределенных случайных величин $\\alpha_i$ с дисперсией $\\sigma^2$\n",
    "\n",
    "Посчитаем дисперсию среднего по определению:\n",
    "\n",
    "$D(\\frac{\\sum_{i=1}^M\\alpha_i}{M}) = E(\\frac{\\sum_{i=1}^M\\alpha_i}{M} - E\\frac{\\sum_{i=1}^M\\alpha_i}{M})^2 = \\frac{1}{M^2}E(\\sum_{i=1}^M(\\alpha_i-E\\alpha_i))^2 = \\frac{1}{M^2}(\\sum_{i=1}^ME(\\alpha_i-E\\alpha_i)^2 + \\sum_{i\\neq j}^ME((\\alpha_i-E\\alpha_i)(\\alpha_j-E\\alpha_j))) = \\frac{1}{M^2}(M \\sigma^2 + M(M-1)\\rho\\sigma^2) = \\rho\\sigma^2 + \\frac{1}{M}(1-\\rho)\\sigma^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
